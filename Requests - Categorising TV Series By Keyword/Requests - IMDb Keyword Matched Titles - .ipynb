{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Scraping TV Titles Matched By Keyword - IMDb\n",
    "A very short project where I had to uses IMDb's keyword search function to search for titles with a given keyword, then filter by tv show. This was used to categorize a preset list of titles and was used by a colleague in the creation of a dataset for modelling.\n",
    "\n",
    "There are 50 reults per page so the np.arange() is dependant on the number of tv shows i.e. 150 results equals 3 pages equals np.arange(1,4,1). So lists, loops and conditionals could be incorporated to futher automate the process but as I had just two hours to do this and there was keyword reserach involved this short script was sufficient.\n",
    "\n",
    "One caveat here is that the regex used to capture the title depends on the title containing a thumbnail image beginning with \"alt=\". Most titles contain an image but obscure titles may not. This regex will suffice for the purpose of this project.\n",
    "\n",
    "\n",
    "NOTE: The xlsx attached in the folder is a follow up which will provide more context to how these scraped lists where used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 342,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import requests as r\n",
    "import re\n",
    "\n",
    "html_pages = []\n",
    "\n",
    "numbers = np.arange(1,2,1)\n",
    "numbers = numbers.astype(str)\n",
    "for num in numbers:\n",
    "    # Paste the filtered link here - the variable num is merged into the link string at the \"page\" location\n",
    "    html = r.get(\"https://www.imdb.com/search/keyword/?keywords=black-lead&ref_=kw_ref_typ&sort=moviemeter,asc&mode=detail&page=\"+num+\"&title_type=tvSeries\")\n",
    "    html_pages.append(html.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Chewing Gum', 'Vagrant Queen', 'Prime']\n",
      "3\n"
     ]
    }
   ],
   "source": [
    "# Join all the pages\n",
    "joined_string = ' '.join(test) \n",
    "# Regex token to extract the titles\n",
    "title_parse = re.compile(r'alt=\"([\\w\\s]+)\"') \n",
    "# Findall create a list of titles \n",
    "titles = title_parse.findall(joined_string)\n",
    "print(titles)\n",
    "print(len(titles))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a dictionary from list and save to csv\n",
    "dictionary = dict()\n",
    "\n",
    "dictionary['Title'] = titles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'Title': ['Chewing Gum', 'Vagrant Queen', 'Prime']}"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dictionary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save to csv\n",
    "df = pd.DataFrame(dictionary, columns=dictionary.keys())\n",
    "df.to_csv('BL.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
